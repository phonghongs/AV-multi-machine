{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "import cv2\n",
    "from lib.utils.augmentations import letterbox_for_img\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img0 = cv2.imread(path, cv2.IMREAD_COLOR |\n",
    "                      cv2.IMREAD_IGNORE_ORIENTATION)  # BGR\n",
    "    h0, w0 = img0.shape[:2]\n",
    "\n",
    "    img, ratio, pad = letterbox_for_img(img0.copy(), new_shape=640, auto=True)\n",
    "    h, w = img.shape[:2]\n",
    "    shapes = (h0, w0), ((h / h0, w / w0), pad)\n",
    "    img = np.ascontiguousarray(img)\n",
    "    return img, img0, shapes\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"/home/YOLOP/tr_export/bb.trt\", \"rb\")\n",
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))\n",
    "\n",
    "engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# need to set input and output precisions to FP16 to fully enable it\n",
    "output = np.empty([1, 1000], dtype=np.float16)\n",
    "\n",
    "# allocate device memory     5000000\n",
    "d_input = cuda.mem_alloc(5000000)\n",
    "d_output = cuda.mem_alloc(5000000)\n",
    "# (1474560,4669440)\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()\n",
    "\n",
    "img, img_det, shapes = load_img(\n",
    "    '/home/YOLOP/inference/images/adb4871d-4d063244.jpg')\n",
    "img = transform(img)\n",
    "if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "img = np.half(img)\n",
    "print(img.shape)\n",
    "\n",
    "input_idx = engine['img']\n",
    "output_idx = engine['out_bb0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod(d_input, batch)\n",
    "    # execute model\n",
    "    context.execute(bindings, None)\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh(output, d_output)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "execute(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt.tensorrt.IExecutionContext, batch_size: int = 1, bindings: List[int]) -> bool\n\nInvoked with: <tensorrt.tensorrt.IExecutionContext object at 0x7f74f01737f0>, [140142289354752, 140142337589248], None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/YOLOP/t_rt.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWarming up...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m pred \u001b[39m=\u001b[39m predict(img)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone warming up!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/YOLOP/t_rt.ipynb Cell 5\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m cuda\u001b[39m.\u001b[39mmemcpy_htod(d_input, batch)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# execute model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m context\u001b[39m.\u001b[39;49mexecute(bindings, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=5'>6</a>\u001b[0m \u001b[39m# transfer predictions back\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f7263687274222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3139322e3136382e342e3632227d7d/home/YOLOP/t_rt.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m cuda\u001b[39m.\u001b[39mmemcpy_dtoh(output, d_output)\n",
      "\u001b[0;31mTypeError\u001b[0m: execute(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt.tensorrt.IExecutionContext, batch_size: int = 1, bindings: List[int]) -> bool\n\nInvoked with: <tensorrt.tensorrt.IExecutionContext object at 0x7f74f01737f0>, [140142289354752, 140142337589248], None"
     ]
    }
   ],
   "source": [
    "print(\"Warming up...\")\n",
    "\n",
    "pred = predict(img)\n",
    "\n",
    "print(\"Done warming up!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
